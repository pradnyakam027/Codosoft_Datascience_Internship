{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPXbGpshGi7Rxx7BYn5M1Ro",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pradnyakam027/Codosoft_Datascience_Internship/blob/main/Credit_Card_Fraud_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbMmmm_LCsM8",
        "outputId": "fd1b02bf-cf08-405c-f657-b1b488c09757"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
            "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
            "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',\n",
            "       'Class'],\n",
            "      dtype='object')\n",
            "Time      0\n",
            "V1        0\n",
            "V2        0\n",
            "V3        0\n",
            "V4        0\n",
            "V5        0\n",
            "V6        0\n",
            "V7        0\n",
            "V8        0\n",
            "V9        0\n",
            "V10       0\n",
            "V11       1\n",
            "V12       1\n",
            "V13       1\n",
            "V14       1\n",
            "V15       1\n",
            "V16       1\n",
            "V17       1\n",
            "V18       1\n",
            "V19       1\n",
            "V20       1\n",
            "V21       1\n",
            "V22       1\n",
            "V23       1\n",
            "V24       1\n",
            "V25       1\n",
            "V26       1\n",
            "V27       1\n",
            "V28       1\n",
            "Amount    1\n",
            "Class     1\n",
            "dtype: int64\n",
            "Logistic Regression Evaluation\n",
            "[[2060   19]\n",
            " [  50  958]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      0.99      0.98      2079\n",
            "         1.0       0.98      0.95      0.97      1008\n",
            "\n",
            "    accuracy                           0.98      3087\n",
            "   macro avg       0.98      0.97      0.97      3087\n",
            "weighted avg       0.98      0.98      0.98      3087\n",
            "\n",
            "Random Forest Evaluation\n",
            "[[2079    0]\n",
            " [  10  998]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00      2079\n",
            "         1.0       1.00      0.99      1.00      1008\n",
            "\n",
            "    accuracy                           1.00      3087\n",
            "   macro avg       1.00      1.00      1.00      3087\n",
            "weighted avg       1.00      1.00      1.00      3087\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.pipeline import Pipeline\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv(\"/content/creditcard.csv\")\n",
        "\n",
        "# Print the column names to identify the target column\n",
        "print(data.columns)\n",
        "\n",
        "# Check for missing values in the dataset\n",
        "print(data.isnull().sum())\n",
        "\n",
        "# Handle missing values if any\n",
        "data = data.dropna()\n",
        "\n",
        "# Preprocess and normalize the transaction data\n",
        "X = data.drop('Class', axis=1)\n",
        "y = data['Class']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Handling class imbalance using SMOTE and undersampling\n",
        "over = SMOTE(sampling_strategy=0.1)  # Oversample the minority class to 10% of the majority class\n",
        "under = RandomUnderSampler(sampling_strategy=0.5)  # Then undersample the majority class to 50% of the new minority class\n",
        "steps = [('o', over), ('u', under)]\n",
        "pipeline = Pipeline(steps=steps)\n",
        "\n",
        "X_resampled, y_resampled = pipeline.fit_resample(X_scaled, y)\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a classification algorithm\n",
        "# Logistic Regression\n",
        "log_reg = LogisticRegression()\n",
        "log_reg.fit(X_train, y_train)\n",
        "\n",
        "# Random Forest\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "# Logistic Regression Evaluation\n",
        "y_pred_log_reg = log_reg.predict(X_test)\n",
        "print(\"Logistic Regression Evaluation\")\n",
        "print(confusion_matrix(y_test, y_pred_log_reg))\n",
        "print(classification_report(y_test, y_pred_log_reg))\n",
        "\n",
        "# Random Forest Evaluation\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "print(\"Random Forest Evaluation\")\n",
        "print(confusion_matrix(y_test, y_pred_rf))\n",
        "print(classification_report(y_test, y_pred_rf))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6uPLztNXCuSG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}